{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "import torchvision.models as models\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from tqdm import tqdm  # For progress bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),  # Convert to 3-channel\n",
    "    transforms.Resize((224, 224)),  # Resize to Inception v3 input size\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "])\n",
    "\n",
    "\n",
    "# Load MNIST dataset\n",
    "mnist_train = datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
    "mnist_test = datasets.MNIST(root=\"./data\", train=False, download=True, transform=transform)\n",
    "\n",
    "# Efficient function: Store only image indices, not full images\n",
    "def organize_by_label(dataset):\n",
    "    label_dict = {}\n",
    "    for idx in range(len(dataset)):\n",
    "        _, label = dataset[idx]  # Get label only\n",
    "        if label not in label_dict:\n",
    "            label_dict[label] = []\n",
    "        label_dict[label].append(idx)  # Store index, not image\n",
    "    return label_dict\n",
    "\n",
    "\n",
    "train_label_dict = organize_by_label(mnist_train)\n",
    "test_label_dict = organize_by_label(mnist_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create positive and negative pairs\n",
    "def create_pairs(dataset, label_dict, num_pairs=1000):\n",
    "    pairs = []\n",
    "    labels = list(label_dict.keys())\n",
    "\n",
    "    for _ in range(num_pairs):\n",
    "        # Positive pair (same digit)\n",
    "        label = random.choice(labels)\n",
    "        if len(label_dict[label]) >= 2:\n",
    "            idx1, idx2 = random.sample(label_dict[label], 2)\n",
    "            pairs.append((idx1, idx2, 0))  # Label 0 for similar images\n",
    "\n",
    "        # Negative pair (different digits)\n",
    "        label1, label2 = random.sample(labels, 2)\n",
    "        idx1 = random.choice(label_dict[label1])\n",
    "        idx2 = random.choice(label_dict[label2])\n",
    "        pairs.append((idx1, idx2, 1))  # Label 1 for dissimilar images\n",
    "\n",
    "    return pairs\n",
    "\n",
    "# Generate pairs using the optimized function\n",
    "train_pairs = create_pairs(mnist_train, train_label_dict, num_pairs=5000)\n",
    "test_pairs = create_pairs(mnist_test, test_label_dict, num_pairs=2500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated Dataset Class (Loads images dynamically)\n",
    "class ContrastiveMNISTDataset(Dataset):\n",
    "    def __init__(self, dataset, pairs):\n",
    "        self.dataset = dataset  # Store reference to dataset\n",
    "        self.pairs = pairs  # Store pairs (indices, not images)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        idx1, idx2, label = self.pairs[idx]  # Get image indices & label\n",
    "        img1, _ = self.dataset[idx1]  # Load image dynamically\n",
    "        img2, _ = self.dataset[idx2]  # Load image dynamically\n",
    "        return (img1, img2), torch.tensor(label, dtype=torch.float32)\n",
    "    \n",
    "# Create dataset instances\n",
    "train_dataset = ContrastiveMNISTDataset(mnist_train, train_pairs)\n",
    "test_dataset = ContrastiveMNISTDataset(mnist_test, test_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset size: 10000 pairs\n",
      "Testing dataset size: 5000 pairs\n"
     ]
    }
   ],
   "source": [
    "# Create DataLoaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True , num_workers= 16, pin_memory=True, prefetch_factor=2, persistent_workers=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=128, shuffle=False , num_workers= 16, pin_memory=True, prefetch_factor=2, persistent_workers=True)\n",
    "\n",
    "print(f\"Training dataset size: {len(train_dataset)} pairs\")\n",
    "print(f\"Testing dataset size: {len(test_dataset)} pairs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use ResNet50 pretrained on ImageNet as the feature extractor\n",
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        # Load pretrained ResNet50 and remove the last fully connected layer\n",
    "        resnet50 = models.resnet50(pretrained=True)\n",
    "        self.feature_extractor = nn.Sequential(*list(resnet50.children())[:-1])  # Remove the FC layer\n",
    "\n",
    "        # Add a fully connected layer for feature comparison (optional)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(2048, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 128)\n",
    "        )\n",
    "\n",
    "    def forward_once(self, x):\n",
    "        \"\"\"Pass the input through the feature extractor.\"\"\"\n",
    "        x = self.feature_extractor(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten the output\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, input1, input2):\n",
    "        \"\"\"Compute embeddings for both inputs and return the distance.\"\"\"\n",
    "        output1 = self.forward_once(input1)\n",
    "        output2 = self.forward_once(input2)\n",
    "        return output1, output2\n",
    "    \n",
    "\n",
    "    # Define the contrastive loss function\n",
    "class ContrastiveLoss(nn.Module):\n",
    "    def __init__(self, margin=1.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, output1, output2, label):\n",
    "        \"\"\"Compute contrastive loss.\"\"\"\n",
    "        euclidean_distance = torch.nn.functional.pairwise_distance(output1, output2)\n",
    "        loss = torch.mean((1 - label) * torch.pow(euclidean_distance, 2) +\n",
    "                          label * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\n",
    "        return loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda3/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/data/anaconda3/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/data/anaconda3/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Create the model, loss function, and optimizer\n",
    "model = SiameseNetwork().cuda()  # Move model to GPU if available\n",
    "criterion = ContrastiveLoss(margin=1.0)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, verbose=True)  # Reduce LR if no improvement\n",
    "\n",
    "# Training loop with validation using the split dataset\n",
    "num_epochs = 50\n",
    "best_val_loss = float('inf')\n",
    "early_stop_counter = 0\n",
    "patience = 10  # Early stopping patience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50: 100%|██████████| 79/79 [00:59<00:00,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Training Loss: 0.0843, Training Accuracy: 0.9071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0307, Validation Accuracy: 0.9824\n",
      "Best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50:  65%|██████▍   | 51/79 [00:36<00:20,  1.38it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     16\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 18\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Compute accuracy\u001b[39;00m\n\u001b[1;32m     21\u001b[0m similarity_scores \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mpairwise_distance(output1, output2)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    # Training phase\n",
    "    for (img1, img2), labels in tqdm(train_dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "        img1, img2, labels = img1.cuda(), img2.cuda(), labels.cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output1, output2 = model(img1, img2)\n",
    "        \n",
    "        loss = criterion(output1, output2, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Compute accuracy\n",
    "        similarity_scores = torch.nn.functional.pairwise_distance(output1, output2)\n",
    "        predictions = (similarity_scores > 0.5).float()  # Assuming 0.5 as the threshold\n",
    "        correct_predictions += (predictions == labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "    \n",
    "    avg_train_loss = total_loss / len(train_dataloader)\n",
    "    train_accuracy = correct_predictions / total_samples\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Training Loss: {avg_train_loss:.4f}, Training Accuracy: {train_accuracy:.4f}\")\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct_val_predictions = 0\n",
    "    total_val_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for (val_img1, val_img2), val_labels in test_dataloader:\n",
    "            val_img1, val_img2, val_labels = val_img1.cuda(), val_img2.cuda(), val_labels.cuda()\n",
    "            val_output1, val_output2 = model(val_img1, val_img2)\n",
    "            val_loss += criterion(val_output1, val_output2, val_labels).item()\n",
    "\n",
    "            # Compute validation accuracy\n",
    "            val_similarity_scores = torch.nn.functional.pairwise_distance(val_output1, val_output2)\n",
    "            val_predictions = (val_similarity_scores > 0.5).float()\n",
    "            correct_val_predictions += (val_predictions == val_labels).sum().item()\n",
    "            total_val_samples += val_labels.size(0)\n",
    "\n",
    "    avg_val_loss = val_loss / len(test_dataloader)\n",
    "    val_accuracy = correct_val_predictions / total_val_samples\n",
    "    print(f\"Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "    # Early stopping and model saving\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        early_stop_counter = 0\n",
    "        torch.save(model.state_dict(), \"best_siamese_model.pth\")\n",
    "        print(\"Best model saved!\")\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "        print(f\"Early stopping counter: {early_stop_counter}/{patience}\")\n",
    "\n",
    "    # Reduce learning rate if validation loss doesn't improve\n",
    "    scheduler.step(avg_val_loss)\n",
    "    \n",
    "    if early_stop_counter >= patience:\n",
    "        print(\"Early stopping triggered. Training stopped.\")\n",
    "        break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
